{
 "metadata": {
  "name": "",
  "signature": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Spark: Creating Scala Applications"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Q: So you've written some Spark code in Scala. How do you submit it to Spark and run it?  \n",
      "A: Use `sbt` or `maven` to package it into a Java jar, and submit it to Spark using `spark-submit`\n",
      "\n",
      "Q: What if I want to run `MySparkScript.py`?  \n",
      "A: `spark-submit --master local[2] /path/to/MySparkScript.py \"An input argument\"`\n",
      "\n",
      "Q: What's a Java jar?  \n",
      "A: JAR (Java Archive) is a package file format typically used to aggregate many Java class files and associated metadata and resources (text, images, etc.) into one file to distribute application software or libraries on the Java platform."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Packaging with `sbt`\n",
      "Create a root directory for your project and run `./mkdirs4sbt` within it. This script will automatically create the proper `sbt` directory structure, which borrows from the Java `maven` directory structure. The script will also generate a template `build.sbt` file at the top of the directory that you should fill out with the appropriate versions and dependencies for your app.\n",
      "\n",
      "**What is SBT?**  \n",
      "SBT is a modern build tool written in/for Scala, though it is also a general purpose build tool  \n",
      "\n",
      "**Why SBT?**\n",
      "- Sane(ish) dependency management\n",
      "- Only-update-on-request model\n",
      "- Full Scala language support for creating tasks\n",
      "- Continuous command execution\n",
      "- Launch REPL in project context"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Project Layout (Directory structure)**   \n",
      "\n",
      "`project` \u2013 project definition files  \n",
      "`project/build/` *yourproject* `.scala` \u2013 the main project definition file  \n",
      "`project/build.properties` \u2013 project, sbt and scala version definitions  \n",
      "`src/main` \u2013 your app code goes here, in a subdirectory indicating the code\u2019s language (e.g. src/main/scala, src/main/java)  \n",
      "`src/main/resources` \u2013 static files you want added to your jar (e.g. logging config)  \n",
      "`src/test` \u2013 like src/main, but for tests  \n",
      "`lib_managed` \u2013 the jar files your project depends on. Populated by sbt update  \n",
      "`target` \u2013 the destination for generated stuff (e.g. generated thrift\n",
      "code, class files, jars)  \n",
      "\n",
      "For an example of a spark project, see `projects/spark_scala_example`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### `build.sbt`: Dependencies and versioning\n",
      "\n",
      "Example `build.sbt` (located in the root directory of your project) \n",
      "```scala\n",
      "import AssemblyKeys._\n",
      "\n",
      "name := \"Hello World\"\n",
      "version := \"1.0\"\n",
      "scalaVersion := \"2.10.4\"\n",
      "\n",
      "libraryDependencies ++= Seq(\n",
      "    // Spark dependency\n",
      "    \"org.apache.spark\" % \"spark-core_2.10\" % \"1.3.0\" % \"provided\",\n",
      "    {other dependencies}\n",
      ")\n",
      "\n",
      "// This statement includes the assembly plug-in capabilities\n",
      "assemblySettings\n",
      "\n",
      "// Configure JAR used with the assembly plug-in\n",
      "jarName in assembly := \"my-project-assembly.jar\"\n",
      "\n",
      "// A special option to exclude Scala itself form our assembly JAR, since Spark\n",
      "// already bundles Scala.\n",
      "assemblyOption in assembly :=\n",
      "(assemblyOption in assembly).value.copy(includeScala = false)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Running (submitting a `jar` to Spark)\n",
      "Side note: Don't put your jar on git.\n",
      "1. Run `sbt assembly` in your project's home directory. The output to console will tell you the name and location of the resulting jar (under `./target`) \n",
      "2. Use spark-submit to run your application locally\n",
      "```bash\n",
      "$ spark-submit \\\n",
      "  --class \"{scala class}\" \\\n",
      "  --master local[*] \\\n",
      "  target/scala-2.10/{your app's jar name}.jar\n",
      "```\n",
      "\n",
      "#### Spark on EMR\n",
      "To create an EMR cluster to run a Spark jar, or to submit a Spark jar as a step to an already-running EMR cluster, put the jar at a location on s3 do something along the lines of:\n",
      "```bash\n",
      "aws emr create-cluster --name \"{Your cluster name}\" \\\n",
      "--ami-version 3.6 --instance-type m3.xlarge --instance-count 1 \\\n",
      "--bootstrap-actions Path=s3://support.elasticmapreduce/spark/install-spark \\\n",
      "--steps Type=CUSTOM_JAR,\\\n",
      "Name=\"higgs_svm\",ActionOnFailure=CONTINUE,\\\n",
      "Jar=s3://thedataincubator-fellow/path/to/higgs.jar,\\\n",
      "Args=[\"s3://thedataincubator-course/input/path/\",\"{second command line argument}\"] \\\n",
      "--ec2-attributes KeyName={keyname} \\\n",
      "--log-uri s3://thedataincubator-fellow/your/log/uri\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**To open an existing Scala application in Eclipse** \n",
      "- Add sbteclipse (the line below) to your plugin definition file. You can use either:  \n",
      "the global file (for version 0.13 and up) at ~/.sbt/0.13/plugins/plugins.sbt  \n",
      "the project-specific file at PROJECT_DIR/project/plugins.sbt\n",
      "\n",
      "<pre><code>addSbtPlugin(\"com.typesafe.sbteclipse\" % \"sbteclipse-plugin\" % \"3.0.0\")</code></pre>\n",
      "\n",
      "- Then, in your project home directory run:  \n",
      "<pre><code>$ sbt eclipse</code></pre>\n",
      "\n",
      "- In Eclipse, use the *Import Wizard* to import *Existing Projects into Workspace*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Packaging with Maven\n",
      "\n",
      "You can use the same `mkdirs4sbt` script to create the appropriate directory structure; however instead of a `build.sbt` file manage dependencies, you'll need to create `pom.xml` in the project's home directory. To package, simply run `$ mvn package`\n",
      "\n",
      "Example `pom.xml`:\n",
      "```xml\n",
      "<project> <modelVersion>4.0.0</modelVersion>\n",
      "  <!-- Information about your project -->\n",
      "<groupId>com.databricks</groupId> <artifactId>example-build</artifactId> <name>Simple Project</name> <packaging>jar</packaging> <version>1.0</version>\n",
      "  <dependencies>\n",
      "    <!-- Spark dependency -->\n",
      "<dependency> <groupId>org.apache.spark</groupId> <artifactId>spark-core_2.10</artifactId> <version>1.2.0</version> <scope>provided</scope>\n",
      "    </dependency>\n",
      "    <!-- Third-party library -->\n",
      "<dependency> <groupId>net.sf.jopt-simple</groupId> <artifactId>jopt-simple</artifactId> <version>4.3</version>\n",
      "    </dependency>\n",
      "    <!-- Third-party library -->\n",
      "<dependency> <groupId>joda-time</groupId> <artifactId>joda-time</artifactId> <version>2.0</version>\n",
      "    </dependency>\n",
      "  </dependencies>\n",
      "  <build>\n",
      "    <plugins>\n",
      "      <!-- Maven shade plug-in that creates uber JARs -->\n",
      "<plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-shade-plugin</artifactId> <version>2.3</version>\n",
      "<executions>\n",
      "<execution> <phase>package</phase> <goals>\n",
      "<goal>shade</goal> </goals>\n",
      "          </execution>\n",
      "\ufffcPackaging Your Code and Dependencies\n",
      "| 125\n",
      "</executions>\n",
      "      </plugin>\n",
      "    </plugins>\n",
      "  </build>\n",
      "</project>\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Copyright &copy; 2015 The Data Incubator.  All rights reserved.*"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}