{
 "metadata": {
  "name": "",
  "signature": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## NLP on the Yelp corpus.\n",
      "\n",
      "We're going to explore a little bit of Natural Language processing with Yelp reviews.  In particular, we are interested in sentiment: are the words predictive of positive or negative **sentiment** in a review.  We're going to use the star ratings as our labels."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Setup\n",
      "\n",
      "What metric should we use?  Should this be a prediction or classification problem?\n",
      "\n",
      "**Exercise:** Use vectorization and a basic regularized linear regression to build a first model.\n",
      "\n",
      "*Hints:* \n",
      "\n",
      "1. Don't forget to use tokenization!  This is important for good performance but it is also the most expensive step.  Try vectorizing as a first initial step:\n",
      "``` python\n",
      "X = (feature_extraction.text\n",
      "        .CountVectorizer()\n",
      "        .fit_transform(text))\n",
      "y = scores\n",
      "```\n",
      "    and then building grid-serach and cross-validation onto of this pre-processed data.  **Challenge:** use pickle to save off these results so that you can directly load them (rather than recomputing them) between python sessions.\n",
      "\n",
      "1. Choose a low `min_df` (minimum document frequency cutoff) and a high `max_df` in `CountVectorizer`.  Setting `min_df` to zero allows super rare words which can make your data unmanagable but we want to use cross-validation at the next step (see below) to select these.\n",
      "\n",
      "1. Try using ridge regression or some other type of regularized linear regression.  Remember that `RidgeCV` uses a warm start and is faster than using `grid_search.GridSearch` with `Ridge`.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Rare words\n",
      "    \n",
      "**Exercise:** Write your own document frequency transformer.  This should find features that are in only a few reviews (or in too many reviews) and throw them out.  This is what the `min_df` and `max_df` in `CountVectorizer` do.  Since `CountVectorizer` is expensive (because of stemming) but this can be done as a cheap post-processing step, you should implement it and cross validate as part of your pipeline."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## TF-IDF and other normalization schemes\n",
      "\n",
      "**Exercise:** [TFIDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) is a common normalization scheme used in text processing.  Use the `TFIDFTransformer`.  There are options for using `idf` and taking the logarithm of `tf`.  Do these significantly affect the result?  Finally, you can use the \"does this word present in this document\" normalization, which is always 1 or 0.\n",
      "\n",
      "If you can't decide, whcih one is better, don't forget that you can combine models with a linear regression."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Dimensionality reduction\n",
      "\n",
      "Sometimes, reducing the dimension can be useful.  Because we are dealing with a sparse matrix, we have to use `TruncatedSVD`.  If we reduce the dimensions, we can use a more sophisticated models than linear ones.\n",
      "\n",
      "**Exercise:** Try a dimensionality reduction strategy and see if this can help."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Copyright &copy; 2014 The Data Incubator.  All rights reserved.*"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}